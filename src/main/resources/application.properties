server.port=9998

security.basic.enabled=false
security.ignored=/**

spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.url=jdbc:mysql://localhost:3306/spring?useUnicode = true&characterEncoding=UTF-8&zeroDateTimeBehavior=convertToNull
spring.datasource.username=mysdc
spring.datasource.password=mysdc

#thymeleaf start
spring.thymeleaf.mode=HTML5
spring.thymeleaf.encoding=UTF-8
spring.thymeleaf.content-type=text/html
#开发时关闭缓存,不然没法看到实时页面
spring.thymeleaf.cache=false
#thymeleaf end

# REDIS (RedisProperties)
# Redis数据库索引（默认为0）
spring.redis.database=0
# Redis服务器地址
spring.redis.host=10.1.11.109
# Redis服务器连接端口
spring.redis.port=6379
# Redis服务器连接密码（默认为空）
#spring.redis.password=123456
# 连接池最大连接数（使用负值表示没有限制）
spring.redis.pool.max-active=8
# 连接池最大阻塞等待时间（使用负值表示没有限制）
spring.redis.pool.max-wait=-1
# 连接池中的最大空闲连接
spring.redis.pool.max-idle=8
# 连接池中的最小空闲连接
spring.redis.pool.min-idle=0
# 连接超时时间（毫秒）
spring.redis.timeout=0


## 消费者的组名
#apache.rocketmq.consumer.PushConsumer=PushConsumer
## 生产者的组名
#apache.rocketmq.producer.producerGroup=Producer
## NameServer地址
#apache.rocketmq.namesrvAddr=10.2.5.17:9876

spring.rocketmq.name-server-address=10.2.5.17:9876
# 可选, 如果无需发送消息则忽略该配置
spring.rocketmq.producer-group=lzwing-producer-group
# 发送超时配置毫秒数, 可选, 默认3000
spring.rocketmq.send-msg-timeout=5000
# 追溯消息具体消费情况的开关，默认打开
#spring.rocketmq.trace-enabled=false
# 是否启用VIP通道，默认打开
spring.rocketmq.vip-channel-enabled=false

#kafka configuration
#spring.kafka.producer.bootstrap-servers=10.2.5.17:32768,10.2.5.17:32769
spring.kafka.producer.bootstrap-servers=10.2.4.107:9093
#指定kafka服务器地址
#spring.kafka.consumer.bootstrap-servers=10.2.5.17:32768,10.2.5.17:32769
spring.kafka.consumer.bootstrap-servers=10.2.4.107:9093

spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#topic
kafka.app.topic.foo=my-replicated-topic

#kafka configuration
#指定消息被消费之后自动提交偏移量，以便下次继续消费
spring.kafka.consumer.enable-auto-commit=true
#指定消息组
#spring.kafka.consumer.group-id=guan

#指定从最近地方开始消费(earliest)
spring.kafka.consumer.auto-offset-reset=latest

#email
spring.mail.host=smtp.exmail.qq.com
spring.mail.username=chenzhongyong@cecdat.com
spring.mail.password=Czy654321
spring.mail.properties.mail.smtp.auth=true
spring.mail.properties.mail.smtp.starttls.enable=true
spring.mail.properties.mail.smtp.starttls.required=true


#elastic-job
regCenter.serverList=10.1.11.109:2181
regCenter.namespace=elastic-job-lite-springboot

simpleJob.cron=0/5 * * * * ?
simpleJob.shardingTotalCount=2
simpleJob.shardingItemParameters=0=Beijing,1=Shanghai,2=Guangzhou

dataflowJob.cron=0/5 * * * * ?
dataflowJob.shardingTotalCount=2
dataflowJob.shardingItemParameters=0=Beijing,1=Shanghai,2=Guangzhou


#hbase
spring.data.hbase.quorum=10.2.4.107:2181
spring.data.hbase.rootDir=hdfs://10.2.4.107:8020/hbase
spring.data.hbase.nodeParent=/hbase

#自定义starter测试
wrapper.service.enabled=true
wrapper.service.suffix=suffix-
wrapper.service.prefix=prefix-